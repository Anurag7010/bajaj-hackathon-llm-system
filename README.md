# Bajaj Hackathon 2025 - Intelligent Document Query System

[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-green.svg)](https://fastapi.tiangolo.com/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

## ğŸ¯ Project Overview

An intelligent document analysis system that processes PDF/DOCX files and answers questions using LLM-powered query understanding and decision making. Built for the Bajaj Hackathon 2025, this system combines advanced NLP techniques with modern API architecture.

## âœ¨ Key Features

- **ğŸ“„ Multi-format Document Processing**: Supports PDF and DOCX file analysis
- **ğŸ” Vector Similarity Search**: Efficient document chunk retrieval using embeddings
- **ğŸ¤– LLM Integration**: Powered by Google's Gemini API for intelligent responses
- **ğŸš€ RESTful API**: FastAPI-based with comprehensive error handling
- **âš¡ Production Ready**: Includes monitoring, logging, and performance optimization
- **ğŸ”„ Real-time Processing**: Handles multiple queries simultaneously

## ğŸ—ï¸ System Architecture

```
Input Document â†’ Document Loader â†’ Text Chunking â†’ Vector Store â†’ Query Processing
                                                        â†“
Response Builder â† Logic Evaluator â† Clause Matcher â† Query Parser
```

### Technical Stack

- **Backend**: FastAPI, Pydantic
- **ML/AI**: Google Gemini API, Sentence Transformers
- **Document Processing**: PyPDF2, pdfplumber, python-docx
- **Vector Search**: Custom vector store with cosine similarity
- **Deployment**: Uvicorn ASGI server

## ğŸš€ Quick Start

### Prerequisites

- Python 3.11 or higher
- Google Gemini API key

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/yourusername/bajaj-hackathon-llm-system.git
   cd bajaj-hackathon-llm-system
   ```

2. **Create and activate virtual environment**
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: .\venv\Scripts\activate
   ```

3. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

4. **Configure environment**
   ```bash
   cp .env.example .env
   # Edit .env and add your GEMINI_API_KEY
   ```

5. **Run the application**
   ```bash
   uvicorn app.main:app --reload
   ```

## ğŸ“¡ API Usage

### Health Check
```bash
GET /api/v1/hackrx/health
```

### Document Query Processing
```bash
POST /api/v1/hackrx/run
```

**Request Format:**
```json
{
  "documents": "https://example.com/policy.pdf",
  "questions": [
    "What is the grace period for premium payment?",
    "What are the coverage limits?",
    "What are the exclusions?"
  ]
}
```

**Response Format:**
```json
{
  "answers": [
    "The grace period for premium payment is thirty days.",
    "Coverage limits include maximum amounts per claim...",
    "Exclusions include pre-existing conditions..."
  ]
}
```

### Testing the API

Run the included test script:
```bash
python test_api.py
```

## ğŸ› ï¸ Project Structure

```
bajaj-hackathon/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/v1/
â”‚   â”‚   â””â”€â”€ endpoints.py         # API route definitions
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â””â”€â”€ config.py           # Configuration settings
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ models.py           # Pydantic data models
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ document_loader.py  # Document processing
â”‚   â”‚   â”œâ”€â”€ query_parser.py     # Query understanding
â”‚   â”‚   â”œâ”€â”€ vector_store.py     # Vector embeddings
â”‚   â”‚   â”œâ”€â”€ clause_matcher.py   # Similarity search
â”‚   â”‚   â”œâ”€â”€ logic_evaluator.py  # LLM integration
â”‚   â”‚   â””â”€â”€ response_builder.py # Response formatting
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ exceptions.py       # Custom exceptions
â”‚   â”‚   â”œâ”€â”€ logging_config.py   # Logging setup
â”‚   â”‚   â””â”€â”€ monitoring.py       # Performance monitoring
â”‚   â””â”€â”€ main.py                 # FastAPI application
â”œâ”€â”€ test_api.py                 # API testing script
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ .env.example               # Environment template
â”œâ”€â”€ .gitignore                 # Git ignore rules
â””â”€â”€ README.md                  # Project documentation
```

## ğŸ”§ Configuration

Create a `.env` file with:
```env
GEMINI_API_KEY=your-gemini-api-key-here
```

Optional configuration in `app/core/config.py`:
- `MAX_CHUNK_SIZE`: Text chunk size (default: 1000)
- `CHUNK_OVERLAP`: Overlap between chunks (default: 200)
- `TOP_K_RESULTS`: Number of similar chunks to retrieve (default: 5)

## ğŸ§ª Development & Testing

### Running Tests
```bash
python test_api.py
```

### Development Mode
```bash
uvicorn app.main:app --reload --host 127.0.0.1 --port 8000
```

## ğŸ“ˆ Performance Features

- **Caching**: Global service initialization for optimal performance
- **Monitoring**: Built-in performance tracking and logging
- **Error Handling**: Comprehensive exception handling with meaningful messages
- **Async Processing**: Non-blocking API operations

## ğŸ† Hackathon Achievements

- âœ… Successfully processes complex policy documents
- âœ… Accurate question-answering with high confidence scores
- âœ… Sub-30 second processing time for 5 complex queries
- âœ… Production-ready architecture with monitoring
- âœ… Clean, maintainable codebase following best practices

## ğŸ¤ Contributing

This project was developed for the Bajaj Hackathon 2025. Feel free to fork and enhance!

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- Bajaj Hackathon 2025 organizers
- Google Gemini API for LLM capabilities
- FastAPI and Python ecosystem
